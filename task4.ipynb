{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"avito_train.tsv\",sep='\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3995803, 13) 0.0688212106553\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>itemid</th>\n",
       "      <th>category</th>\n",
       "      <th>subcategory</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>attrs</th>\n",
       "      <th>price</th>\n",
       "      <th>is_proved</th>\n",
       "      <th>is_blocked</th>\n",
       "      <th>phones_cnt</th>\n",
       "      <th>emails_cnt</th>\n",
       "      <th>urls_cnt</th>\n",
       "      <th>close_hours</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10000010</td>\n",
       "      <td>Транспорт</td>\n",
       "      <td>Автомобили с пробегом</td>\n",
       "      <td>Toyota Sera, 1991</td>\n",
       "      <td>Новая оригинальная линзованая оптика на ксенон...</td>\n",
       "      <td>{\"Год выпуска\":\"1991\", \"Тип кузова\":\"Купе\", \"П...</td>\n",
       "      <td>150000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10000025</td>\n",
       "      <td>Услуги</td>\n",
       "      <td>Предложения услуг</td>\n",
       "      <td>Монтаж кровли</td>\n",
       "      <td>Выполняем  монтаж кровли фальцевой ^p Тел:8@@P...</td>\n",
       "      <td>{\"Вид услуги\":\"Ремонт, строительство\"}</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10000094</td>\n",
       "      <td>Личные вещи</td>\n",
       "      <td>Одежда, обувь, аксессуары</td>\n",
       "      <td>Костюм Steilmann</td>\n",
       "      <td>Юбка и топ из панбархата. Под топ  трикотажная...</td>\n",
       "      <td>{\"Вид одежды\":\"Женская одежда\", \"Предмет одежд...</td>\n",
       "      <td>1500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000101</td>\n",
       "      <td>Транспорт</td>\n",
       "      <td>Автомобили с пробегом</td>\n",
       "      <td>Ford Focus, 2011</td>\n",
       "      <td>Автомобиль в отличном техническом состоянии, в...</td>\n",
       "      <td>{\"Марка\":\"Ford\", \"Модель\":\"Focus\", \"Год выпуск...</td>\n",
       "      <td>365000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10000132</td>\n",
       "      <td>Транспорт</td>\n",
       "      <td>Запчасти и аксессуары</td>\n",
       "      <td>Турбина 3.0 Bar</td>\n",
       "      <td>Продам турбину на двигатель V-6 . V-8 и мощнее...</td>\n",
       "      <td>{\"Вид товара\":\"Запчасти\", \"Тип товара\":\"Для ав...</td>\n",
       "      <td>5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     itemid     category                subcategory              title  \\\n",
       "0  10000010    Транспорт      Автомобили с пробегом  Toyota Sera, 1991   \n",
       "1  10000025       Услуги          Предложения услуг      Монтаж кровли   \n",
       "2  10000094  Личные вещи  Одежда, обувь, аксессуары   Костюм Steilmann   \n",
       "3  10000101    Транспорт      Автомобили с пробегом   Ford Focus, 2011   \n",
       "4  10000132    Транспорт      Запчасти и аксессуары    Турбина 3.0 Bar   \n",
       "\n",
       "                                         description  \\\n",
       "0  Новая оригинальная линзованая оптика на ксенон...   \n",
       "1  Выполняем  монтаж кровли фальцевой ^p Тел:8@@P...   \n",
       "2  Юбка и топ из панбархата. Под топ  трикотажная...   \n",
       "3  Автомобиль в отличном техническом состоянии, в...   \n",
       "4  Продам турбину на двигатель V-6 . V-8 и мощнее...   \n",
       "\n",
       "                                               attrs   price  is_proved  \\\n",
       "0  {\"Год выпуска\":\"1991\", \"Тип кузова\":\"Купе\", \"П...  150000        NaN   \n",
       "1             {\"Вид услуги\":\"Ремонт, строительство\"}       0        NaN   \n",
       "2  {\"Вид одежды\":\"Женская одежда\", \"Предмет одежд...    1500        NaN   \n",
       "3  {\"Марка\":\"Ford\", \"Модель\":\"Focus\", \"Год выпуск...  365000        NaN   \n",
       "4  {\"Вид товара\":\"Запчасти\", \"Тип товара\":\"Для ав...    5000        NaN   \n",
       "\n",
       "   is_blocked  phones_cnt  emails_cnt  urls_cnt  close_hours  \n",
       "0           0           0           0         0         0.03  \n",
       "1           0           1           0         0        22.38  \n",
       "2           0           0           0         0         0.41  \n",
       "3           0           0           0         0         8.87  \n",
       "4           0           0           0         0        11.82  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print df.shape, df.is_blocked.mean()\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blocked ratio 0.0688212106553\n",
      "Count: 3995803\n"
     ]
    }
   ],
   "source": [
    "print \"Blocked ratio\",df.is_blocked.mean()\n",
    "print \"Count:\",len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Balance-out the classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def downsampleDataset(df):\n",
    "    indexes = [i for i,val in enumerate(df.is_blocked) if val != 0]\n",
    "    notBlocked = [i for i,val in enumerate(df.is_blocked) if val == 0]\n",
    "    indexes.extend(np.random.choice(notBlocked, len(indexes), replace=False))\n",
    "    return df.loc[indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Blocked ratio: 0.5\n",
      "Count: 549992\n"
     ]
    }
   ],
   "source": [
    "df = downsampleDataset(df)\n",
    "\n",
    "\n",
    "print \"Blocked ratio:\",df.is_blocked.mean()\n",
    "print \"Count:\",len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All tests passed\n"
     ]
    }
   ],
   "source": [
    "assert df.is_blocked.mean() < 0.51\n",
    "assert df.is_blocked.mean() > 0.49\n",
    "assert len(df) <= 560000\n",
    "\n",
    "print \"All tests passed\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tokenizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import RegexpTokenizer\n",
    "from collections import Counter,defaultdict\n",
    "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
    "\n",
    "#Dictionary of tokens\n",
    "token_counts = Counter()\n",
    "\n",
    "#All texts\n",
    "all_texts = np.hstack([df.description.values,df.title.values])\n",
    "\n",
    "\n",
    "#Compute token frequencies\n",
    "for s in all_texts:\n",
    "    if type(s) is not str:\n",
    "        continue\n",
    "    s = s.decode('utf8').lower()\n",
    "    tokens = tokenizer.tokenize(s)\n",
    "    for token in tokens:\n",
    "        token_counts[token] +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique keys: 520990\n"
     ]
    }
   ],
   "source": [
    "print \"Unique keys:\", len(token_counts.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove rare tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEACAYAAABPiSrXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n3QwNSVK3/w9b8LRu1OlaNgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1e83fca10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Word frequency distribution, just for kicks\n",
    "_=plt.hist(token_counts.values(),range=[0,50],bins=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Select only the tokens that had at least 10 occurences in the corpora.\n",
    "#Use token_counts.\n",
    "\n",
    "min_count = 10\n",
    "tokens = [token for token in token_counts.keys() if token_counts[token] >= min_count]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "token_to_id = {t:i+1 for i,t in enumerate(tokens)}\n",
    "null_token = \"NULL\"\n",
    "token_to_id[null_token] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Tokens: 87815\n"
     ]
    }
   ],
   "source": [
    "print \"# Tokens:\",len(token_to_id)\n",
    "if len(token_to_id) < 30000:\n",
    "    print \"Alarm! It seems like there are too few tokens. Make sure you updated NLTK and applied correct thresholds -- unless you now what you're doing, ofc\"\n",
    "if len(token_to_id) > 1000000:\n",
    "    print \"Alarm! Too many tokens. You might have messed up when pruning rare ones -- unless you know what you're doin' ofc\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace words with IDs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set a maximum length for titles and descriptions.\n",
    "\n",
    "* If string is longer that that limit - crop it, if less - pad with zeros.\n",
    "* Thus we obtain a matrix of size [n_samples]x[max_length]\n",
    "* Element at i,j - is an identifier of word j within sample i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def vectorize(strings, token_to_id, max_len=150):\n",
    "    token_matrix = []\n",
    "    for s in strings:\n",
    "        if type(s) is not str:\n",
    "            token_matrix.append([0]*max_len)\n",
    "            continue\n",
    "        s = s.decode('utf8').lower()\n",
    "        tokens = tokenizer.tokenize(s)\n",
    "        token_ids = map(lambda token: token_to_id.get(token,0), tokens)[:max_len]\n",
    "        token_ids += [0]*(max_len - len(token_ids))\n",
    "        token_matrix.append(token_ids)\n",
    "\n",
    "    return np.array(token_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "desc_tokens = vectorize(df.description.values,token_to_id,max_len = 150)\n",
    "title_tokens = vectorize(df.title.values,token_to_id,max_len = 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Размер матрицы: (549992, 15)\n",
      "Поездки на таможню, печать в паспорте -> [43256 14662 55278 81971 80069 17315     0     0     0     0] ...\n",
      "Рефлекторно-урогинекологический массаж -> [ 8344     0 30437     0     0     0     0     0     0     0] ...\n",
      "Возьму суду под200 т. р -> [28798 23377     0  3665 33922     0     0     0     0     0] ...\n"
     ]
    }
   ],
   "source": [
    "print \"Размер матрицы:\",title_tokens.shape\n",
    "for title, tokens in zip(df.title.values[:3],title_tokens[:3]):\n",
    "    print title,'->', tokens[:10],'...'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#All numeric features\n",
    "df_numerical_features = df[[\"phones_cnt\",\"emails_cnt\",\"urls_cnt\",\"price\"]]\n",
    "data_cat_subcat = df[[\"category\",\"subcategory\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#One-hot-encoded category and subcategory\n",
    "\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "categories = []\n",
    "data_cat_subcat = df[[\"category\",\"subcategory\"]].values\n",
    "\n",
    "categories =[{\"category\":category_name, \"subcategory\":subcategory_name} \\\n",
    "             for category_name, subcategory_name in data_cat_subcat ]\n",
    "vectorizer = DictVectorizer(sparse=False)\n",
    "cat_one_hot = vectorizer.fit_transform(categories)\n",
    "cat_one_hot = pd.DataFrame(cat_one_hot,columns=vectorizer.feature_names_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_non_text = pd.merge(\n",
    "    df_numerical_features,cat_one_hot,on = np.arange(len(cat_one_hot))\n",
    ")\n",
    "del df_non_text[\"key_0\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split data into training and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Target variable - whether or not sample contains prohibited material\n",
    "target = df.is_blocked.values.astype('int32')\n",
    "#Preprocessed titles\n",
    "title_tokens = title_tokens.astype('int32')\n",
    "#Preprocessed tokens\n",
    "desc_tokens = desc_tokens.astype('int32')\n",
    "\n",
    "#Non-sequences\n",
    "df_non_text = df_non_text.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ShuffleSplit\n",
    "#Split into training and test set.\n",
    "\n",
    "\n",
    "#Difficulty selector:\n",
    "#Easy: split randomly\n",
    "#Medium: select test set items that have item_ids strictly above that of training set\n",
    "#Hard: do whatever you want, but score yourself using kaggle private leaderboard\n",
    "\n",
    "rs = ShuffleSplit(n_splits=1, test_size=.25, random_state=0)\n",
    "for indexes_train, indexes_test  in rs.split(title_tokens):\n",
    "    \n",
    "\n",
    "    title_tr = np.array([title_tokens[i] for i in indexes_train])\n",
    "    title_ts = np.array([title_tokens[i] for i in indexes_test])\n",
    "    desc_tr =  np.array([desc_tokens[i] for i in indexes_train])\n",
    "    desc_ts =  np.array([desc_tokens[i] for i in indexes_test])\n",
    "    nontext_tr = np.array(df_non_text.iloc[indexes_train])\n",
    "    nontext_ts =  np.array(df_non_text.iloc[indexes_test])\n",
    "    target_tr = np.array([target[i] for i in indexes_train])\n",
    "    target_ts =  np.array([target[i] for i in indexes_test])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## NN architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#libraries\n",
    "import lasagne\n",
    "from theano import tensor as T\n",
    "import theano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "#3 inputs and a refere output\n",
    "title_token_ids = T.matrix(\"title_token_ids\",dtype='int32')\n",
    "desc_token_ids = T.matrix(\"desc_token_ids\",dtype='int32')\n",
    "categories = T.matrix(\"categories\",dtype='float32')\n",
    "target_y = T.ivector(\"is_blocked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "title_inp = lasagne.layers.InputLayer((None,title_tr.shape[1]),input_var=title_token_ids)\n",
    "descr_inp = lasagne.layers.InputLayer((None,desc_tr.shape[1]),input_var=desc_token_ids)\n",
    "cat_inp = lasagne.layers.InputLayer((None,nontext_tr.shape[1]), input_var=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Descriptions\n",
    "number = 64\n",
    "#word-wise embedding. We recommend to start from some 64 and improving after you are certain it works.\n",
    "descr_nn = lasagne.layers.EmbeddingLayer(descr_inp, input_size=len(token_to_id)+1, output_size=number)\n",
    "descr_nn = lasagne.layers.LSTMLayer(descr_nn,64 )\n",
    "\n",
    "# Titles\n",
    "title_nn = lasagne.layers.EmbeddingLayer(title_inp, input_size=len(token_to_id)+1, output_size=number)\n",
    "title_nn = lasagne.layers.LSTMLayer(title_nn, 64)\n",
    "\n",
    "# Non-sequences\n",
    "cat_nn = lasagne.layers.GRULayer(cat_inp, number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут сначала не использовала нечисловые признаки. Позже запустила с числовыми, и, действительно, без них оказалось лучше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 165, 64)\n"
     ]
    }
   ],
   "source": [
    "nn = lasagne.layers.concat([descr_nn, title_nn])# <merge three layers into one (e.g. lasagne.layers.concat) >                                  \n",
    "print nn.output_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "nn = lasagne.layers.DenseLayer(nn,64)\n",
    "nn = lasagne.layers.DropoutLayer(nn,p=0.5)\n",
    "nn = lasagne.layers.DenseLayer(nn,1,nonlinearity=lasagne.nonlinearities.linear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#All trainable params\n",
    "weights = lasagne.layers.get_all_params(nn,trainable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Simple NN prediction\n",
    "prediction = lasagne.layers.get_output(nn)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Hinge loss\n",
    "loss = lasagne.objectives.binary_hinge_loss(prediction,target_y,delta =1 ).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "det_prediction = lasagne.layers.get_output(nn,deterministic=True)[:,0]\n",
    "#Hinge loss\n",
    "det_loss = lasagne.objectives.binary_hinge_loss(det_prediction,target_y,delta =1 ).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Weight optimization step\n",
    "updates = lasagne.updates.adadelta(loss, weights)\n",
    "#updates = lasagne.updates.adadelta(loss_train, all_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_fun = theano.function([desc_token_ids,title_token_ids,target_y],[loss,prediction],updates = updates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "eval_fun = theano.function([desc_token_ids,title_token_ids,target_y],[det_loss,det_prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#average precision at K\n",
    "\n",
    "from oracle import APatK, score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Out good old minibatch iterator now supports arbitrary amount of arrays (X,y,z)\n",
    "\n",
    "def iterate_minibatches(*arrays,**kwargs):\n",
    "    batchsize=kwargs.get(\"batchsize\",100)\n",
    "    shuffle = kwargs.get(\"shuffle\",True)\n",
    "    \n",
    "    if shuffle:\n",
    "        indices = np.arange(len(arrays[0]))\n",
    "        np.random.shuffle(indices)\n",
    "    for start_idx in range(0, len(arrays[0]) - batchsize + 1, batchsize):\n",
    "        if shuffle:\n",
    "            excerpt = indices[start_idx:start_idx + batchsize]\n",
    "        else:\n",
    "            excerpt = slice(start_idx, start_idx + batchsize)\n",
    "        yield [arr[excerpt] for arr in arrays]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      "\tloss: 0.864696721522\n",
      "\tacc: 0.596534653465\n",
      "\tauc: 0.643573037034\n",
      "Val:\n",
      "\tloss: 0.764258313031\n",
      "\tacc: 0.648217821782\n",
      "\tauc: 0.875010719689\n",
      "\tap@k: 0.99164756436\n",
      "Train:\n",
      "\tloss: 0.488303093047\n",
      "\tacc: 0.79603960396\n",
      "\tauc: 0.879005975908\n",
      "Val:\n",
      "\tloss: 0.355185203504\n",
      "\tacc: 0.860594059406\n",
      "\tauc: 0.938052484355\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.351300105209\n",
      "\tacc: 0.853861386139\n",
      "\tauc: 0.93052008221\n",
      "Val:\n",
      "\tloss: 0.316821248845\n",
      "\tacc: 0.861485148515\n",
      "\tauc: 0.946163521273\n",
      "\tap@k: 0.998776659036\n",
      "Train:\n",
      "\tloss: 0.273409001672\n",
      "\tacc: 0.891683168317\n",
      "\tauc: 0.953693336318\n",
      "Val:\n",
      "\tloss: 0.241953628912\n",
      "\tacc: 0.900891089109\n",
      "\tauc: 0.968014759408\n",
      "\tap@k: 0.988199956186\n",
      "Train:\n",
      "\tloss: 0.245245072665\n",
      "\tacc: 0.899801980198\n",
      "\tauc: 0.962713537096\n",
      "Val:\n",
      "\tloss: 0.244623440317\n",
      "\tacc: 0.89900990099\n",
      "\tauc: 0.964838834011\n",
      "\tap@k: 0.985982487608\n",
      "Train:\n",
      "\tloss: 0.202843000562\n",
      "\tacc: 0.91801980198\n",
      "\tauc: 0.971709382368\n",
      "Val:\n",
      "\tloss: 0.195683669133\n",
      "\tacc: 0.919900990099\n",
      "\tauc: 0.975883270611\n",
      "\tap@k: 0.99930268158\n",
      "Train:\n",
      "\tloss: 0.191344739806\n",
      "\tacc: 0.923663366337\n",
      "\tauc: 0.973615670803\n",
      "Val:\n",
      "\tloss: 0.177742706314\n",
      "\tacc: 0.925544554455\n",
      "\tauc: 0.978307441812\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.182539048185\n",
      "\tacc: 0.926633663366\n",
      "\tauc: 0.976375164082\n",
      "Val:\n",
      "\tloss: 0.169812291983\n",
      "\tacc: 0.931287128713\n",
      "\tauc: 0.980719533161\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.171847855638\n",
      "\tacc: 0.930198019802\n",
      "\tauc: 0.978374643479\n",
      "Val:\n",
      "\tloss: 0.153494558283\n",
      "\tacc: 0.939702970297\n",
      "\tauc: 0.982318486111\n",
      "\tap@k: 0.994941725776\n",
      "Train:\n",
      "\tloss: 0.168393447686\n",
      "\tacc: 0.933168316832\n",
      "\tauc: 0.978661370991\n",
      "Val:\n",
      "\tloss: 0.169227654142\n",
      "\tacc: 0.92900990099\n",
      "\tauc: 0.982613626115\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.151099510294\n",
      "\tacc: 0.941287128713\n",
      "\tauc: 0.98155843836\n",
      "Val:\n",
      "\tloss: 0.159853924283\n",
      "\tacc: 0.935247524752\n",
      "\tauc: 0.98393621068\n",
      "\tap@k: 0.994342089897\n",
      "Train:\n",
      "\tloss: 0.151989863532\n",
      "\tacc: 0.939702970297\n",
      "\tauc: 0.982126950109\n",
      "Val:\n",
      "\tloss: 0.159591127008\n",
      "\tacc: 0.934257425743\n",
      "\tauc: 0.984855798009\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.139522243225\n",
      "\tacc: 0.944653465347\n",
      "\tauc: 0.984777825891\n",
      "Val:\n",
      "\tloss: 0.152667035477\n",
      "\tacc: 0.937722772277\n",
      "\tauc: 0.982698006449\n",
      "\tap@k: 0.997701019347\n",
      "Train:\n",
      "\tloss: 0.146048018022\n",
      "\tacc: 0.944356435644\n",
      "\tauc: 0.982328554273\n",
      "Val:\n",
      "\tloss: 0.15139990749\n",
      "\tacc: 0.93702970297\n",
      "\tauc: 0.984277506399\n",
      "\tap@k: 0.997639139411\n",
      "Train:\n",
      "\tloss: 0.136433357056\n",
      "\tacc: 0.946831683168\n",
      "\tauc: 0.985512197461\n",
      "Val:\n",
      "\tloss: 0.142853840451\n",
      "\tacc: 0.94198019802\n",
      "\tauc: 0.985387585367\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.131716774516\n",
      "\tacc: 0.947524752475\n",
      "\tauc: 0.985390255857\n",
      "Val:\n",
      "\tloss: 0.155672428714\n",
      "\tacc: 0.937821782178\n",
      "\tauc: 0.984619710136\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.131259754764\n",
      "\tacc: 0.949603960396\n",
      "\tauc: 0.985492333872\n",
      "Val:\n",
      "\tloss: 0.130604397151\n",
      "\tacc: 0.947227722772\n",
      "\tauc: 0.987418362851\n",
      "\tap@k: 0.98869162921\n",
      "Train:\n",
      "\tloss: 0.127035790136\n",
      "\tacc: 0.950693069307\n",
      "\tauc: 0.985839332577\n",
      "Val:\n",
      "\tloss: 0.136150751563\n",
      "\tacc: 0.946138613861\n",
      "\tauc: 0.984944667748\n",
      "\tap@k: 0.995514801667\n",
      "Train:\n",
      "\tloss: 0.128658696735\n",
      "\tacc: 0.949702970297\n",
      "\tauc: 0.986195791367\n",
      "Val:\n",
      "\tloss: 0.132931041351\n",
      "\tacc: 0.945940594059\n",
      "\tauc: 0.986196459039\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.113360808171\n",
      "\tacc: 0.95603960396\n",
      "\tauc: 0.98888562242\n",
      "Val:\n",
      "\tloss: 0.130675558422\n",
      "\tacc: 0.947227722772\n",
      "\tauc: 0.987133594023\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.117924100875\n",
      "\tacc: 0.954455445545\n",
      "\tauc: 0.987556908161\n",
      "Val:\n",
      "\tloss: 0.137606047911\n",
      "\tacc: 0.944158415842\n",
      "\tauc: 0.986707456267\n",
      "\tap@k: 0.998807966637\n",
      "Train:\n",
      "\tloss: 0.122870815798\n",
      "\tacc: 0.952871287129\n",
      "\tauc: 0.986696139588\n",
      "Val:\n",
      "\tloss: 0.123899337455\n",
      "\tacc: 0.948811881188\n",
      "\tauc: 0.988542947682\n",
      "\tap@k: 0.99725249186\n",
      "Train:\n",
      "\tloss: 0.114004681301\n",
      "\tacc: 0.955148514851\n",
      "\tauc: 0.988438342789\n",
      "Val:\n",
      "\tloss: 0.138713890085\n",
      "\tacc: 0.944356435644\n",
      "\tauc: 0.98508130466\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.125185951621\n",
      "\tacc: 0.950891089109\n",
      "\tauc: 0.987004046678\n",
      "Val:\n",
      "\tloss: 0.118433751033\n",
      "\tacc: 0.953564356436\n",
      "\tauc: 0.988471460285\n",
      "\tap@k: 0.999606874898\n",
      "Train:\n",
      "\tloss: 0.110516862541\n",
      "\tacc: 0.957524752475\n",
      "\tauc: 0.989605953679\n",
      "Val:\n",
      "\tloss: 0.12955369753\n",
      "\tacc: 0.947425742574\n",
      "\tauc: 0.987452833326\n",
      "\tap@k: 0.994066755804\n",
      "Train:\n",
      "\tloss: 0.116095165723\n",
      "\tacc: 0.95396039604\n",
      "\tauc: 0.988633377658\n",
      "Val:\n",
      "\tloss: 0.126778149271\n",
      "\tacc: 0.948217821782\n",
      "\tauc: 0.988971293476\n",
      "\tap@k: 0.996788901353\n",
      "Train:\n",
      "\tloss: 0.111404424785\n",
      "\tacc: 0.959306930693\n",
      "\tauc: 0.987449287123\n",
      "Val:\n",
      "\tloss: 0.130262436752\n",
      "\tacc: 0.945544554455\n",
      "\tauc: 0.98772782868\n",
      "\tap@k: 0.998635620671\n",
      "Train:\n",
      "\tloss: 0.106477694649\n",
      "\tacc: 0.960396039604\n",
      "\tauc: 0.98910761161\n",
      "Val:\n",
      "\tloss: 0.124978339724\n",
      "\tacc: 0.95\n",
      "\tauc: 0.987694943755\n",
      "\tap@k: 0.994997395764\n",
      "Train:\n",
      "\tloss: 0.0979580820489\n",
      "\tacc: 0.961386138614\n",
      "\tauc: 0.991915914278\n",
      "Val:\n",
      "\tloss: 0.109966354437\n",
      "\tacc: 0.956237623762\n",
      "\tauc: 0.989982489384\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.110980314263\n",
      "\tacc: 0.957524752475\n",
      "\tauc: 0.987995058177\n",
      "Val:\n",
      "\tloss: 0.131677396969\n",
      "\tacc: 0.948217821782\n",
      "\tauc: 0.989519198734\n",
      "\tap@k: 0.994997395764\n",
      "Train:\n",
      "\tloss: 0.101764792801\n",
      "\tacc: 0.959801980198\n",
      "\tauc: 0.990604781574\n",
      "Val:\n",
      "\tloss: 0.105732315937\n",
      "\tacc: 0.959900990099\n",
      "\tauc: 0.990269140544\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.10457466224\n",
      "\tacc: 0.959108910891\n",
      "\tauc: 0.990269328112\n",
      "Val:\n",
      "\tloss: 0.11574422908\n",
      "\tacc: 0.954356435644\n",
      "\tauc: 0.989108026916\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.104635245811\n",
      "\tacc: 0.959207920792\n",
      "\tauc: 0.989864848041\n",
      "Val:\n",
      "\tloss: 0.111032029501\n",
      "\tacc: 0.956336633663\n",
      "\tauc: 0.989843901429\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.101806275462\n",
      "\tacc: 0.961584158416\n",
      "\tauc: 0.98964087412\n",
      "Val:\n",
      "\tloss: 0.123896999114\n",
      "\tacc: 0.950198019802\n",
      "\tauc: 0.987530979627\n",
      "\tap@k: 0.998897584029\n",
      "Train:\n",
      "\tloss: 0.0997909300767\n",
      "\tacc: 0.961881188119\n",
      "\tauc: 0.990341147312\n",
      "Val:\n",
      "\tloss: 0.117471261135\n",
      "\tacc: 0.952178217822\n",
      "\tauc: 0.989750770643\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.0971381957302\n",
      "\tacc: 0.96198019802\n",
      "\tauc: 0.990854970824\n",
      "Val:\n",
      "\tloss: 0.114985029587\n",
      "\tacc: 0.95396039604\n",
      "\tauc: 0.990175975572\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.0956865542089\n",
      "\tacc: 0.963366336634\n",
      "\tauc: 0.991302018325\n",
      "Val:\n",
      "\tloss: 0.112186791132\n",
      "\tacc: 0.954455445545\n",
      "\tauc: 0.989884422813\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.0981984164168\n",
      "\tacc: 0.961485148515\n",
      "\tauc: 0.990698661655\n",
      "Val:\n",
      "\tloss: 0.11086993659\n",
      "\tacc: 0.957524752475\n",
      "\tauc: 0.990164417136\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.101338334118\n",
      "\tacc: 0.961584158416\n",
      "\tauc: 0.989927410302\n",
      "Val:\n",
      "\tloss: 0.107254367875\n",
      "\tacc: 0.960198019802\n",
      "\tauc: 0.98945438687\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.0970646317585\n",
      "\tacc: 0.96504950495\n",
      "\tauc: 0.990149131782\n",
      "Val:\n",
      "\tloss: 0.10712658435\n",
      "\tacc: 0.957227722772\n",
      "\tauc: 0.990275714548\n",
      "\tap@k: 0.992550679356\n",
      "Train:\n",
      "\tloss: 0.0938517917598\n",
      "\tacc: 0.96495049505\n",
      "\tauc: 0.991720083459\n",
      "Val:\n",
      "\tloss: 0.115006274787\n",
      "\tacc: 0.955148514851\n",
      "\tauc: 0.989140795363\n",
      "\tap@k: 0.994787581066\n",
      "Train:\n",
      "\tloss: 0.0965012666537\n",
      "\tacc: 0.964059405941\n",
      "\tauc: 0.990416084151\n",
      "Val:\n",
      "\tloss: 0.112532527876\n",
      "\tacc: 0.954653465347\n",
      "\tauc: 0.990744939244\n",
      "\tap@k: 0.993033274641\n",
      "Train:\n",
      "\tloss: 0.0823677666515\n",
      "\tacc: 0.96801980198\n",
      "\tauc: 0.993312535767\n",
      "Val:\n",
      "\tloss: 0.104780453371\n",
      "\tacc: 0.958118811881\n",
      "\tauc: 0.991391476814\n",
      "\tap@k: 0.99939460577\n",
      "Train:\n",
      "\tloss: 0.0921758693137\n",
      "\tacc: 0.965346534653\n",
      "\tauc: 0.991688454196\n",
      "Val:\n",
      "\tloss: 0.11472118344\n",
      "\tacc: 0.954653465347\n",
      "\tauc: 0.989507632659\n",
      "\tap@k: 0.988955133822\n",
      "Train:\n",
      "\tloss: 0.0923758151492\n",
      "\tacc: 0.966336633663\n",
      "\tauc: 0.991519166711\n",
      "Val:\n",
      "\tloss: 0.0965605307711\n",
      "\tacc: 0.963069306931\n",
      "\tauc: 0.991751037245\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.0908375662733\n",
      "\tacc: 0.964554455446\n",
      "\tauc: 0.992314870105\n",
      "Val:\n",
      "\tloss: 0.100676325922\n",
      "\tacc: 0.960297029703\n",
      "\tauc: 0.991750594605\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.0935160314053\n",
      "\tacc: 0.965247524752\n",
      "\tauc: 0.991014087693\n",
      "Val:\n",
      "\tloss: 0.104069123304\n",
      "\tacc: 0.958910891089\n",
      "\tauc: 0.992036146752\n",
      "\tap@k: 0.998068312187\n",
      "Train:\n",
      "\tloss: 0.0841768876954\n",
      "\tacc: 0.968613861386\n",
      "\tauc: 0.993028041391\n",
      "Val:\n",
      "\tloss: 0.106360410026\n",
      "\tacc: 0.958415841584\n",
      "\tauc: 0.990640156863\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.0856107365782\n",
      "\tacc: 0.967920792079\n",
      "\tauc: 0.992925431747\n",
      "Val:\n",
      "\tloss: 0.104888018408\n",
      "\tacc: 0.959207920792\n",
      "\tauc: 0.991601233856\n",
      "\tap@k: 0.996753610557\n",
      "Train:\n",
      "\tloss: 0.0845266145244\n",
      "\tacc: 0.968811881188\n",
      "\tauc: 0.992499040028\n",
      "Val:\n",
      "\tloss: 0.0983761600242\n",
      "\tacc: 0.961386138614\n",
      "\tauc: 0.992082640917\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.087930896398\n",
      "\tacc: 0.967326732673\n",
      "\tauc: 0.991910319735\n",
      "Val:\n",
      "\tloss: 0.113816644965\n",
      "\tacc: 0.955247524752\n",
      "\tauc: 0.990390144262\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.0896131174187\n",
      "\tacc: 0.965544554455\n",
      "\tauc: 0.992033921524\n",
      "Val:\n",
      "\tloss: 0.105847974762\n",
      "\tacc: 0.957920792079\n",
      "\tauc: 0.991366228061\n",
      "\tap@k: 0.992339838184\n",
      "Train:\n",
      "\tloss: 0.0829794532332\n",
      "\tacc: 0.969504950495\n",
      "\tauc: 0.992836425273\n",
      "Val:\n",
      "\tloss: 0.107072206209\n",
      "\tacc: 0.957722772277\n",
      "\tauc: 0.99150377304\n",
      "\tap@k: 0.994724532813\n",
      "Train:\n",
      "\tloss: 0.0795962441994\n",
      "\tacc: 0.970198019802\n",
      "\tauc: 0.993482877224\n",
      "Val:\n",
      "\tloss: 0.112922841403\n",
      "\tacc: 0.95702970297\n",
      "\tauc: 0.989248847881\n",
      "\tap@k: 0.994885260502\n",
      "Train:\n",
      "\tloss: 0.0771516744619\n",
      "\tacc: 0.971287128713\n",
      "\tauc: 0.993475264828\n",
      "Val:\n",
      "\tloss: 0.109064856982\n",
      "\tacc: 0.957623762376\n",
      "\tauc: 0.990773744124\n",
      "\tap@k: 0.999092592633\n",
      "Train:\n",
      "\tloss: 0.0824728149938\n",
      "\tacc: 0.968910891089\n",
      "\tauc: 0.992627575864\n",
      "Val:\n",
      "\tloss: 0.101568975281\n",
      "\tacc: 0.959504950495\n",
      "\tauc: 0.991541393481\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.0869275581657\n",
      "\tacc: 0.967326732673\n",
      "\tauc: 0.992072485599\n",
      "Val:\n",
      "\tloss: 0.10181109427\n",
      "\tacc: 0.958613861386\n",
      "\tauc: 0.992048256106\n",
      "\tap@k: 0.99609976296\n",
      "Train:\n",
      "\tloss: 0.0853424840198\n",
      "\tacc: 0.968415841584\n",
      "\tauc: 0.991674781956\n",
      "Val:\n",
      "\tloss: 0.110610859994\n",
      "\tacc: 0.957623762376\n",
      "\tauc: 0.98966182694\n",
      "\tap@k: 0.997467824351\n",
      "Train:\n",
      "\tloss: 0.0818228591617\n",
      "\tacc: 0.969306930693\n",
      "\tauc: 0.99232894404\n",
      "Val:\n",
      "\tloss: 0.0991180531237\n",
      "\tacc: 0.961188118812\n",
      "\tauc: 0.99178566831\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.0848770827403\n",
      "\tacc: 0.968613861386\n",
      "\tauc: 0.992080782947\n",
      "Val:\n",
      "\tloss: 0.09791321072\n",
      "\tacc: 0.962178217822\n",
      "\tauc: 0.991856580941\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.076388642709\n",
      "\tacc: 0.971386138614\n",
      "\tauc: 0.993530319542\n",
      "Val:\n",
      "\tloss: 0.10069314143\n",
      "\tacc: 0.960693069307\n",
      "\tauc: 0.99159918533\n",
      "\tap@k: 0.996823879841\n",
      "Train:\n",
      "\tloss: 0.0791034238917\n",
      "\tacc: 0.970792079208\n",
      "\tauc: 0.992536796332\n",
      "Val:\n",
      "\tloss: 0.108738198035\n",
      "\tacc: 0.958514851485\n",
      "\tauc: 0.989450331611\n",
      "\tap@k: 0.997639139411\n",
      "Train:\n",
      "\tloss: 0.0781421968962\n",
      "\tacc: 0.970693069307\n",
      "\tauc: 0.993053090362\n",
      "Val:\n",
      "\tloss: 0.0950040302556\n",
      "\tacc: 0.961683168317\n",
      "\tauc: 0.991564058636\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.0846926914343\n",
      "\tacc: 0.967722772277\n",
      "\tauc: 0.992108884183\n",
      "Val:\n",
      "\tloss: 0.106995034578\n",
      "\tacc: 0.95801980198\n",
      "\tauc: 0.990692484122\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.0753538691822\n",
      "\tacc: 0.972277227723\n",
      "\tauc: 0.992900869521\n",
      "Val:\n",
      "\tloss: 0.0986302182795\n",
      "\tacc: 0.96198019802\n",
      "\tauc: 0.99144073724\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.0762418891462\n",
      "\tacc: 0.972673267327\n",
      "\tauc: 0.993072443878\n",
      "Val:\n",
      "\tloss: 0.0977890137392\n",
      "\tacc: 0.962376237624\n",
      "\tauc: 0.992037082589\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.0834969328245\n",
      "\tacc: 0.968910891089\n",
      "\tauc: 0.992086087704\n",
      "Val:\n",
      "\tloss: 0.0922452861959\n",
      "\tacc: 0.963267326733\n",
      "\tauc: 0.992070157719\n",
      "\tap@k: 0.998501243131\n",
      "Train:\n",
      "\tloss: 0.0725578238374\n",
      "\tacc: 0.973168316832\n",
      "\tauc: 0.993680865157\n",
      "Val:\n",
      "\tloss: 0.10245274595\n",
      "\tacc: 0.958811881188\n",
      "\tauc: 0.991833933664\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.0772603192755\n",
      "\tacc: 0.97198019802\n",
      "\tauc: 0.992260075943\n",
      "Val:\n",
      "\tloss: 0.10031686011\n",
      "\tacc: 0.960099009901\n",
      "\tauc: 0.991644257267\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.0787458077452\n",
      "\tacc: 0.969504950495\n",
      "\tauc: 0.992812396517\n",
      "Val:\n",
      "\tloss: 0.0989259595875\n",
      "\tacc: 0.960297029703\n",
      "\tauc: 0.991107561158\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.0773750930605\n",
      "\tacc: 0.97198019802\n",
      "\tauc: 0.992387675193\n",
      "Val:\n",
      "\tloss: 0.0946094259446\n",
      "\tacc: 0.962079207921\n",
      "\tauc: 0.991754193838\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.0726570253788\n",
      "\tacc: 0.973168316832\n",
      "\tauc: 0.994076184892\n",
      "Val:\n",
      "\tloss: 0.105039583411\n",
      "\tacc: 0.958118811881\n",
      "\tauc: 0.991015477536\n",
      "\tap@k: 0.99575014036\n",
      "Train:\n",
      "\tloss: 0.0723781384116\n",
      "\tacc: 0.973366336634\n",
      "\tauc: 0.99399778047\n",
      "Val:\n",
      "\tloss: 0.0993840742488\n",
      "\tacc: 0.961584158416\n",
      "\tauc: 0.991787530881\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.0742270005005\n",
      "\tacc: 0.972376237624\n",
      "\tauc: 0.993757000298\n",
      "Val:\n",
      "\tloss: 0.0969828322127\n",
      "\tacc: 0.962871287129\n",
      "\tauc: 0.992042589888\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.0778747934665\n",
      "\tacc: 0.971584158416\n",
      "\tauc: 0.992751897655\n",
      "Val:\n",
      "\tloss: 0.0994496683568\n",
      "\tacc: 0.960891089109\n",
      "\tauc: 0.991584887272\n",
      "\tap@k: 0.992550679356\n",
      "Train:\n",
      "\tloss: 0.0692282581111\n",
      "\tacc: 0.974653465347\n",
      "\tauc: 0.99379388031\n",
      "Val:\n",
      "\tloss: 0.0996238271913\n",
      "\tacc: 0.961089108911\n",
      "\tauc: 0.992042697655\n",
      "\tap@k: 0.996546165052\n",
      "Train:\n",
      "\tloss: 0.0669529156633\n",
      "\tacc: 0.974653465347\n",
      "\tauc: 0.994474336444\n",
      "Val:\n",
      "\tloss: 0.0982013565734\n",
      "\tacc: 0.961287128713\n",
      "\tauc: 0.992628918328\n",
      "\tap@k: 0.998591333834\n",
      "Train:\n",
      "\tloss: 0.0657925446725\n",
      "\tacc: 0.974554455446\n",
      "\tauc: 0.995114196136\n",
      "Val:\n",
      "\tloss: 0.0954954567993\n",
      "\tacc: 0.96297029703\n",
      "\tauc: 0.992475714793\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.0691800082738\n",
      "\tacc: 0.973465346535\n",
      "\tauc: 0.994168168385\n",
      "Val:\n",
      "\tloss: 0.0857837041723\n",
      "\tacc: 0.965247524752\n",
      "\tauc: 0.993861718073\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.0712031032596\n",
      "\tacc: 0.973465346535\n",
      "\tauc: 0.993953113304\n",
      "Val:\n",
      "\tloss: 0.0983921343761\n",
      "\tacc: 0.962079207921\n",
      "\tauc: 0.99250807279\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.063528465071\n",
      "\tacc: 0.975742574257\n",
      "\tauc: 0.994800377628\n",
      "Val:\n",
      "\tloss: 0.0952519426384\n",
      "\tacc: 0.960396039604\n",
      "\tauc: 0.993015704343\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.0675527828847\n",
      "\tacc: 0.975643564356\n",
      "\tauc: 0.994299108574\n",
      "Val:\n",
      "\tloss: 0.0912184358512\n",
      "\tacc: 0.96297029703\n",
      "\tauc: 0.992900923183\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.0742855092042\n",
      "\tacc: 0.97297029703\n",
      "\tauc: 0.992741586488\n",
      "Val:\n",
      "\tloss: 0.095804121336\n",
      "\tacc: 0.962079207921\n",
      "\tauc: 0.992129844788\n",
      "\tap@k: 0.998314657093\n",
      "Train:\n",
      "\tloss: 0.0719079623842\n",
      "\tacc: 0.97297029703\n",
      "\tauc: 0.993994663422\n",
      "Val:\n",
      "\tloss: 0.0930394566838\n",
      "\tacc: 0.962574257426\n",
      "\tauc: 0.99249984587\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.0613582748923\n",
      "\tacc: 0.976831683168\n",
      "\tauc: 0.995518039216\n",
      "Val:\n",
      "\tloss: 0.101406849104\n",
      "\tacc: 0.96198019802\n",
      "\tauc: 0.991465119851\n",
      "\tap@k: 0.999840921636\n",
      "Train:\n",
      "\tloss: 0.0700186526417\n",
      "\tacc: 0.974158415842\n",
      "\tauc: 0.993675960938\n",
      "Val:\n",
      "\tloss: 0.0945699136775\n",
      "\tacc: 0.964059405941\n",
      "\tauc: 0.992300734871\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.0633243098563\n",
      "\tacc: 0.975940594059\n",
      "\tauc: 0.99444849767\n",
      "Val:\n",
      "\tloss: 0.09975345617\n",
      "\tacc: 0.960792079208\n",
      "\tauc: 0.991782178365\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.0646139164719\n",
      "\tacc: 0.97495049505\n",
      "\tauc: 0.994445498594\n",
      "Val:\n",
      "\tloss: 0.0900136961052\n",
      "\tacc: 0.96504950495\n",
      "\tauc: 0.992893191141\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.0694199475722\n",
      "\tacc: 0.973465346535\n",
      "\tauc: 0.993621327694\n",
      "Val:\n",
      "\tloss: 0.102324104512\n",
      "\tacc: 0.961287128713\n",
      "\tauc: 0.991806228567\n",
      "\tap@k: 0.99836213583\n",
      "Train:\n",
      "\tloss: 0.0645096888064\n",
      "\tacc: 0.976732673267\n",
      "\tauc: 0.994317455507\n",
      "Val:\n",
      "\tloss: 0.0955173441843\n",
      "\tacc: 0.96099009901\n",
      "\tauc: 0.992810790978\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.0676327652276\n",
      "\tacc: 0.976138613861\n",
      "\tauc: 0.993635391017\n",
      "Val:\n",
      "\tloss: 0.0864645829905\n",
      "\tacc: 0.965940594059\n",
      "\tauc: 0.993378902605\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.0725176215693\n",
      "\tacc: 0.973861386139\n",
      "\tauc: 0.993485102916\n",
      "Val:\n",
      "\tloss: 0.0953240663371\n",
      "\tacc: 0.962673267327\n",
      "\tauc: 0.990909297672\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.0694412527495\n",
      "\tacc: 0.973663366337\n",
      "\tauc: 0.994075376262\n",
      "Val:\n",
      "\tloss: 0.0966904185619\n",
      "\tacc: 0.961584158416\n",
      "\tauc: 0.992266704091\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.0643235696853\n",
      "\tacc: 0.97603960396\n",
      "\tauc: 0.994700634317\n",
      "Val:\n",
      "\tloss: 0.0907079173602\n",
      "\tacc: 0.964158415842\n",
      "\tauc: 0.992413299558\n",
      "\tap@k: 0.996858551501\n",
      "Train:\n",
      "\tloss: 0.061688630618\n",
      "\tacc: 0.976831683168\n",
      "\tauc: 0.994901842788\n",
      "Val:\n",
      "\tloss: 0.0947153428403\n",
      "\tacc: 0.963168316832\n",
      "\tauc: 0.992053189291\n",
      "\tap@k: 1.0\n",
      "Train:\n",
      "\tloss: 0.0625717629164\n",
      "\tacc: 0.975643564356\n",
      "\tauc: 0.995084119562\n",
      "Val:\n",
      "\tloss: 0.0932337872628\n",
      "\tacc: 0.963366336634\n",
      "\tauc: 0.992404956012\n",
      "\tap@k: 0.999952945111\n",
      "Train:\n",
      "\tloss: 0.0664206202567\n",
      "\tacc: 0.97504950495\n",
      "\tauc: 0.994223973586\n",
      "Val:\n",
      "\tloss: 0.0844967134648\n",
      "\tacc: 0.965247524752\n",
      "\tauc: 0.99322063204\n",
      "\tap@k: 0.998569002935\n",
      "Train:\n",
      "\tloss: 0.0598623977824\n",
      "\tacc: 0.977128712871\n",
      "\tauc: 0.995574546548\n",
      "Val:\n",
      "\tloss: 0.0906794558926\n",
      "\tacc: 0.965742574257\n",
      "\tauc: 0.992638267722\n",
      "\tap@k: 0.997157626152\n",
      "Train:\n",
      "\tloss: 0.0641498066213\n",
      "\tacc: 0.976534653465\n",
      "\tauc: 0.994724133284\n",
      "Val:\n",
      "\tloss: 0.0960638804455\n",
      "\tacc: 0.960396039604\n",
      "\tauc: 0.992710612597\n",
      "\tap@k: 0.992230044596\n",
      "Train:\n",
      "\tloss: 0.0621878575606\n",
      "\tacc: 0.976435643564\n",
      "\tauc: 0.994793687076\n",
      "Val:\n",
      "\tloss: 0.100815164539\n",
      "\tacc: 0.961584158416\n",
      "\tauc: 0.991873610288\n",
      "\tap@k: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score, accuracy_score\n",
    "\n",
    "n_epochs = 100\n",
    "batch_size = 100\n",
    "minibatches_per_epoch = 100\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    #training\n",
    "    epoch_y_true = []\n",
    "    epoch_y_pred = []\n",
    "    \n",
    "    b_c = b_loss = 0\n",
    "    for j, (b_desc,b_title, b_y) in enumerate(\n",
    "        iterate_minibatches(desc_tr,title_tr,target_tr,batchsize=batch_size,shuffle=True)):\n",
    "        if j > minibatches_per_epoch:break\n",
    "            \n",
    "        loss,pred_probas = train_fun(b_desc,b_title,b_y)\n",
    "        \n",
    "        b_loss += loss\n",
    "        b_c +=1\n",
    "        \n",
    "        epoch_y_true.append(b_y)\n",
    "        epoch_y_pred.append(pred_probas)\n",
    "    \n",
    "    epoch_y_true = np.concatenate(epoch_y_true)\n",
    "    epoch_y_pred = np.concatenate(epoch_y_pred)\n",
    "    \n",
    "    print \"Train:\"\n",
    "    print '\\tloss:',b_loss/b_c\n",
    "    print '\\tacc:',accuracy_score(epoch_y_true,epoch_y_pred>0.)\n",
    "    print '\\tauc:',roc_auc_score(epoch_y_true,epoch_y_pred)\n",
    "    #print '\\tap@k:',APatK(epoch_y_true,epoch_y_pred,K = int(len(epoch_y_pred)*0.025)+1)\n",
    "    \n",
    "    #evaluation\n",
    "    epoch_y_true = []\n",
    "    epoch_y_pred = []\n",
    "    b_c = b_loss = 0\n",
    "    for j, (b_desc,b_title, b_y) in enumerate(\n",
    "        iterate_minibatches(desc_ts,title_ts,target_ts,batchsize=batch_size,shuffle=True)):\n",
    "        if j > minibatches_per_epoch: break\n",
    "        loss,pred_probas = eval_fun(b_desc,b_title,b_y)\n",
    "        \n",
    "        b_loss += loss\n",
    "        b_c +=1\n",
    "        \n",
    "        epoch_y_true.append(b_y)\n",
    "        epoch_y_pred.append(pred_probas)\n",
    "\n",
    "    epoch_y_true = np.concatenate(epoch_y_true)\n",
    "    epoch_y_pred = np.concatenate(epoch_y_pred)\n",
    "    \n",
    "    print \"Val:\"\n",
    "    print '\\tloss:',b_loss/b_c\n",
    "    print '\\tacc:',accuracy_score(epoch_y_true,epoch_y_pred>0.)\n",
    "    print '\\tauc:',roc_auc_score(epoch_y_true,epoch_y_pred)\n",
    "    \n",
    "    print '\\tap@k:',APatK(epoch_y_true,epoch_y_pred,K = int(len(epoch_y_pred)*0.025)+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Scores:\n",
      "\tloss: 0.0938195829858\n",
      "\tacc: 0.96385007278\n",
      "\tauc: 0.992700494464\n",
      "\tap@k: 0.998638497952\n",
      "\n",
      "AUC:\n",
      "\tПиши статью. (great)\n",
      "\n",
      "Accuracy:\n",
      "\tОтличный результат! (good)\n",
      "\n",
      "Average precision at K:\n",
      "\tЗасабмить на kaggle! (great) \n",
      "\t Нет, ну честно - выкачай avito_test.tsv, засабмить и скажи, что вышло.\n"
     ]
    }
   ],
   "source": [
    "#evaluation\n",
    "epoch_y_true = []\n",
    "epoch_y_pred = []\n",
    "\n",
    "b_c = b_loss = 0\n",
    "for j, (b_desc,b_title, b_y) in enumerate(\n",
    "    iterate_minibatches(desc_ts,title_ts,target_ts,batchsize=batch_size,shuffle=True)):\n",
    "    loss,pred_probas = eval_fun(b_desc,b_title,b_y)\n",
    "\n",
    "    b_loss += loss\n",
    "    b_c +=1\n",
    "\n",
    "    epoch_y_true.append(b_y)\n",
    "    epoch_y_pred.append(pred_probas)\n",
    "\n",
    "\n",
    "epoch_y_true = np.concatenate(epoch_y_true)\n",
    "epoch_y_pred = np.concatenate(epoch_y_pred)\n",
    "\n",
    "final_accuracy = accuracy_score(epoch_y_true,epoch_y_pred>0)\n",
    "final_auc = roc_auc_score(epoch_y_true,epoch_y_pred)\n",
    "final_apatk = APatK(epoch_y_true,epoch_y_pred,K = int(len(epoch_y_pred)*0.025)+1)\n",
    "\n",
    "print \"Scores:\"\n",
    "print '\\tloss:',b_loss/b_c\n",
    "print '\\tacc:',final_accuracy\n",
    "print '\\tauc:',final_auc\n",
    "print '\\tap@k:',final_apatk\n",
    "score(final_accuracy,final_auc,final_apatk)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
